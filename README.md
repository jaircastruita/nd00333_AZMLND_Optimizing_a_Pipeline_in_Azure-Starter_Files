# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contains data about direct marketing campaings (phone calls) of a portuguese banking institution. We seek to predict if the client will suscribe a term deposit (variable y).
Dataset source:
https://archive.ics.uci.edu/ml/datasets/bank+marketing

For this problem the best performing model was a voting ensemble model, with an accuracy of 0.9475, most probably because of the flexibility of its decision boundaries of the different participating models in the ensemble.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The pipeline architecture for the dataset transforms categorical features with two categories to binary and with more than two variables replaces the column with an equivalent of dummy variables. The model implemented is a logistic regression with a fixed l2 regularization and hyperparameters C (inverse regularization strength) and max_iter (max number of iterations) for hyperparameter tuning.

**What are the benefits of the parameter sampler you chose?**
For the parameter space search a random parameter sampler was used with C and max_iter, uniform (0.05, 0.1) and choice (100, 150, 200, 250, 300) samplers were selected respectively.
The benefits for these parameter samplers is that makes easier the sampling mechanism to select the hyperparameter's values. In the case of the C hyperparameter only the min-max limits have to be chosen, the sampler will explore that space inbetween. In the case of max_iter, one specific set of values can be passed and the sampler will randomly select one of them.

**What are the benefits of the early stopping policy you chose?**
Using the bandit policy any model which metric falls above the top 10% will be stopped to not waste resources.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
In contrast one thing that AutoML does in addition to select the most appropiate hyperparameters is selecting different kinds of feature transformations and models. Sometimes there exist a better performing model than the one we have in mind to achieve a better performance metric.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
The performance for the logistic regression and the ensemble model were .9156 and .9475 respectively, giving the lead to the latter. The architecture for both models is in principle different: logistic regression uses a dimension-1 decision hyperplane passed through a logistic function to separate one class versus the other, in contrast the voting ensemble uses several different models with probably different decision function finding mechanisms in order to average them and include them to the ensemble to emit a vote over some observation. some really interesting difference between each one is the intepretability the voting ensemble has to lose in order to (most often than not) increase the evaluation metric.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
azureml is an in-development library and some models are not implemented yet (catboost for example). Including more models to this experimentation process could find an even better model to achieve better results.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
The proof of cluster deletion is denoted on the output of the last cell on this notebook
